{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tkinter import filedialog as fd\n",
    "# from rdkit import Chem, DataStructs, RDLogger\n",
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "# from rdkit.Chem import Draw, Descriptors, AllChem\n",
    "# from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
    "\n",
    "# IPythonConsole.ipython_useSVG=True\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import accuracy_score, cohen_kappa_score, matthews_corrcoef\n",
    "import joblib\n",
    "\n",
    "\n",
    "import MachineLearning as ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = pd.read_csv('tested_molecules-1.csv')\n",
    "smiles = smiles['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 15:11:29.242 python[41192:1959379] +[CATransaction synchronize] called within transaction\n",
      "2023-06-19 15:11:29.554 python[41192:1959379] +[CATransaction synchronize] called within transaction\n",
      "2023-06-19 15:11:33.931 python[41192:1959379] +[CATransaction synchronize] called within transaction\n",
      "2023-06-19 15:11:34.031 python[41192:1959379] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All molecules stored in: AllTestedMols.txt\n"
     ]
    }
   ],
   "source": [
    "allAHDL1inhibitors = ML.importFiles(nrFiles=2)\n",
    "ML.writeNewMolfile(allAHDL1inhibitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDescrs = ML.createDescriptorDf()\n",
    "# allDescrs = allDescrs.drop(columns=[\"SMILES\"])\n",
    "x = ML.generateMorganFingerprint()\n",
    "y = allAHDL1inhibitors[1][1:].astype(int)\n",
    "sum(y)/len(y)\n",
    "x, xDims = ML.CombineDescriptorsAndFigerprints(x,allDescrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1\n",
      "TRAIN: [   0    1    2 ... 1597 1598 1599]\n",
      "TEST: [   6   16   23   26   32   34   35   36   37   39   40   41   42   43\n",
      "   48   53   55   59   63   67   71   84   87   94   98  110  119  123\n",
      "  129  131  135  139  141  142  155  162  164  170  177  184  186  187\n",
      "  192  200  204  205  210  214  218  233  236  240  242  261  263  288\n",
      "  292  297  299  308  316  318  321  323  329  348  349  352  355  363\n",
      "  367  373  377  385  387  390  392  393  396  397  406  408  414  423\n",
      "  425  436  439  442  449  457  458  460  461  462  464  467  470  471\n",
      "  476  483  484  492  503  504  507  510  522  523  528  539  540  546\n",
      "  554  558  562  576  584  586  590  594  604  605  607  609  614  615\n",
      "  626  628  635  642  648  652  656  663  665  680  681  683  687  692\n",
      "  702  709  710  716  729  732  739  742  743  745  746  750  753  761\n",
      "  766  768  774  777  780  798  813  826  839  840  842  847  848  859\n",
      "  864  873  877  881  893  895  899  901  904  909  910  913  915  922\n",
      "  925  927  928  930  935  936  941  953  959  965  966  987  994 1003\n",
      " 1005 1018 1026 1035 1041 1045 1052 1058 1061 1062 1069 1070 1074 1082\n",
      " 1084 1087 1092 1097 1103 1104 1107 1111 1125 1146 1147 1151 1157 1161\n",
      " 1164 1168 1169 1171 1175 1180 1181 1184 1186 1190 1193 1195 1200 1203\n",
      " 1206 1207 1209 1230 1239 1242 1246 1251 1260 1261 1272 1276 1277 1279\n",
      " 1283 1285 1286 1288 1289 1293 1295 1296 1299 1305 1318 1326 1327 1328\n",
      " 1329 1331 1332 1334 1342 1346 1352 1359 1367 1369 1370 1375 1378 1382\n",
      " 1390 1395 1400 1406 1414 1415 1418 1419 1435 1436 1437 1439 1445 1452\n",
      " 1462 1467 1469 1474 1482 1485 1490 1492 1494 1501 1511 1518 1523 1537\n",
      " 1538 1546 1553 1567 1570 1572 1573 1576 1586 1589 1595 1596]\n",
      "\n",
      "Fold_2\n",
      "TRAIN: [   0    1    3 ... 1595 1596 1597]\n",
      "TEST: [   2    4    8   13   20   21   24   49   52   69   72   89   91  100\n",
      "  104  105  108  109  114  117  120  137  145  150  152  169  176  189\n",
      "  198  201  207  215  219  222  223  226  228  234  238  248  249  255\n",
      "  257  266  269  273  274  275  276  282  283  301  306  307  330  331\n",
      "  332  339  341  342  344  346  359  360  366  371  374  379  382  386\n",
      "  388  394  395  399  400  402  407  410  411  412  419  421  424  426\n",
      "  427  434  435  445  448  453  456  466  473  474  479  480  481  482\n",
      "  493  502  505  511  517  518  519  524  526  536  541  551  552  557\n",
      "  564  567  569  574  581  589  592  595  596  601  617  620  630  636\n",
      "  640  644  650  651  660  666  667  673  677  700  703  706  711  712\n",
      "  713  714  715  717  718  738  741  744  747  749  751  755  758  762\n",
      "  767  769  775  781  790  794  797  799  806  808  814  817  818  822\n",
      "  823  834  836  843  846  849  851  855  856  860  863  884  888  902\n",
      "  907  908  918  919  924  934  937  938  949  956  958  961  962  969\n",
      "  975  976  977  986  990  993 1000 1001 1002 1004 1007 1011 1012 1013\n",
      " 1014 1017 1019 1023 1024 1027 1034 1039 1040 1048 1049 1053 1060 1068\n",
      " 1073 1075 1076 1080 1086 1094 1098 1109 1121 1129 1137 1138 1139 1144\n",
      " 1145 1154 1165 1178 1179 1191 1197 1202 1212 1232 1245 1250 1254 1255\n",
      " 1265 1267 1268 1307 1308 1311 1319 1321 1325 1335 1336 1339 1341 1344\n",
      " 1347 1361 1362 1366 1368 1376 1380 1387 1389 1391 1398 1403 1404 1410\n",
      " 1412 1417 1423 1424 1425 1428 1433 1441 1448 1449 1458 1463 1484 1491\n",
      " 1496 1502 1515 1517 1521 1522 1528 1530 1532 1533 1540 1541 1549 1552\n",
      " 1554 1555 1558 1559 1560 1562 1568 1581 1582 1592 1598 1599]\n",
      "\n",
      "Fold_3\n",
      "TRAIN: [   1    2    3 ... 1597 1598 1599]\n",
      "TEST: [   0   14   15   19   25   28   30   33   44   45   51   56   57   60\n",
      "   62   78   80   81   82   83   86   88   90   93   95   96  101  103\n",
      "  106  112  113  115  118  124  130  136  144  146  149  160  161  163\n",
      "  167  185  194  195  203  224  229  230  232  237  239  241  244  245\n",
      "  247  251  259  260  265  267  270  271  272  278  281  285  300  311\n",
      "  314  325  326  327  334  347  350  353  365  369  383  391  404  405\n",
      "  409  417  420  429  432  446  450  452  459  468  472  486  487  489\n",
      "  508  509  527  530  542  545  547  548  563  570  573  577  580  582\n",
      "  583  585  597  602  606  608  610  611  616  627  633  639  645  654\n",
      "  662  664  675  676  682  694  695  697  701  708  719  724  727  731\n",
      "  733  734  735  737  757  759  760  763  764  771  778  779  782  784\n",
      "  785  788  789  791  792  793  795  800  804  807  809  812  819  821\n",
      "  827  828  835  837  844  845  861  865  866  869  871  872  874  876\n",
      "  883  885  889  890  897  906  911  914  920  921  932  933  954  984\n",
      "  989  992  995  997  998 1009 1016 1022 1029 1030 1031 1032 1050 1054\n",
      " 1057 1064 1071 1081 1083 1089 1090 1091 1093 1100 1115 1116 1124 1152\n",
      " 1158 1162 1167 1170 1174 1183 1187 1199 1201 1204 1210 1211 1213 1218\n",
      " 1227 1228 1231 1235 1236 1237 1238 1243 1247 1256 1259 1262 1269 1270\n",
      " 1273 1275 1280 1281 1284 1294 1297 1298 1300 1302 1306 1309 1310 1314\n",
      " 1315 1316 1345 1348 1354 1355 1371 1381 1384 1388 1392 1396 1405 1407\n",
      " 1408 1411 1420 1427 1430 1442 1450 1451 1453 1455 1460 1464 1475 1477\n",
      " 1480 1481 1483 1486 1488 1495 1498 1499 1500 1504 1505 1507 1519 1527\n",
      " 1531 1534 1544 1545 1548 1556 1557 1561 1571 1583 1585 1590]\n",
      "\n",
      "Fold_4\n",
      "TRAIN: [   0    2    3 ... 1597 1598 1599]\n",
      "TEST: [   1    5    9   10   18   22   46   58   66   68   74   92   99  107\n",
      "  111  122  125  126  132  138  140  147  148  151  153  156  157  166\n",
      "  168  172  175  178  179  180  182  193  197  199  202  206  216  217\n",
      "  225  227  231  246  252  253  262  264  268  291  293  294  298  302\n",
      "  305  309  310  315  319  320  335  337  338  343  345  356  357  361\n",
      "  362  364  368  372  375  378  380  381  384  403  415  418  428  430\n",
      "  440  441  443  444  455  463  465  477  478  494  496  499  506  516\n",
      "  520  521  525  531  533  534  535  538  543  549  550  553  555  559\n",
      "  561  572  575  579  587  591  593  598  599  600  612  613  618  619\n",
      "  622  623  625  629  631  632  634  641  646  649  655  658  659  669\n",
      "  671  672  674  678  679  684  685  688  689  690  691  696  698  705\n",
      "  707  723  725  726  730  736  740  748  752  754  756  770  773  783\n",
      "  786  802  803  805  811  815  825  831  838  841  852  853  858  862\n",
      "  867  868  886  892  894  898  900  905  916  923  926  929  931  960\n",
      "  967  970  972  978  980  985  988  996  999 1006 1010 1015 1021 1033\n",
      " 1037 1038 1046 1055 1056 1063 1067 1077 1079 1085 1095 1099 1101 1105\n",
      " 1112 1113 1118 1119 1126 1130 1131 1132 1134 1141 1149 1150 1153 1155\n",
      " 1160 1163 1166 1172 1173 1176 1177 1182 1188 1189 1192 1198 1205 1208\n",
      " 1214 1215 1220 1223 1233 1241 1244 1248 1252 1253 1258 1266 1274 1278\n",
      " 1287 1292 1303 1313 1324 1333 1349 1351 1353 1356 1363 1364 1365 1372\n",
      " 1373 1383 1385 1386 1394 1401 1416 1429 1438 1440 1443 1444 1446 1454\n",
      " 1461 1468 1470 1476 1478 1489 1493 1506 1508 1512 1513 1516 1525 1535\n",
      " 1542 1543 1547 1563 1564 1566 1578 1580 1588 1591 1593 1594]\n",
      "\n",
      "Fold_5\n",
      "TRAIN: [   0    1    2 ... 1596 1598 1599]\n",
      "TEST: [   3    7   11   12   17   27   29   31   38   47   50   54   61   64\n",
      "   65   70   73   75   76   77   79   85   97  102  116  121  127  128\n",
      "  133  134  143  154  158  159  165  171  173  174  181  183  188  190\n",
      "  191  196  208  209  211  212  213  220  221  235  243  250  254  256\n",
      "  258  277  279  280  284  286  287  289  290  295  296  303  304  312\n",
      "  313  317  322  324  328  333  336  340  351  354  358  370  376  389\n",
      "  398  401  413  416  422  431  433  437  438  447  451  454  469  475\n",
      "  485  488  490  491  495  497  498  500  501  512  513  514  515  529\n",
      "  532  537  544  556  560  565  566  568  571  578  588  603  621  624\n",
      "  637  638  643  647  653  657  661  668  670  686  693  699  704  720\n",
      "  721  722  728  765  772  776  787  796  801  810  816  820  824  829\n",
      "  830  832  833  850  854  857  870  875  878  879  880  882  887  891\n",
      "  896  903  912  917  939  940  942  943  944  945  946  947  948  950\n",
      "  951  952  955  957  963  964  968  971  973  974  979  981  982  983\n",
      "  991 1008 1020 1025 1028 1036 1042 1043 1044 1047 1051 1059 1065 1066\n",
      " 1072 1078 1088 1096 1102 1106 1108 1110 1114 1117 1120 1122 1123 1127\n",
      " 1128 1133 1135 1136 1140 1142 1143 1148 1156 1159 1185 1194 1196 1216\n",
      " 1217 1219 1221 1222 1224 1225 1226 1229 1234 1240 1249 1257 1263 1264\n",
      " 1271 1282 1290 1291 1301 1304 1312 1317 1320 1322 1323 1330 1337 1338\n",
      " 1340 1343 1350 1357 1358 1360 1374 1377 1379 1393 1397 1399 1402 1409\n",
      " 1413 1421 1422 1426 1431 1432 1434 1447 1456 1457 1459 1465 1466 1471\n",
      " 1472 1473 1479 1487 1497 1503 1509 1510 1514 1520 1524 1526 1529 1536\n",
      " 1539 1550 1551 1565 1569 1574 1575 1577 1579 1584 1587 1597]\n"
     ]
    }
   ],
   "source": [
    "xScale = ML.scaleData(x,scaletype='standardize')\n",
    "# PCA not needed in testing the models\n",
    "# xPrep, _ = ML.PCAfeatureReduction(xScale, 0.999)\n",
    "xPrep = xScale\n",
    "\n",
    "# splitting is stil done due to the  seed, data is split the same as\n",
    "# in training so model still sees unseen samples (default: seed =13)\n",
    "xTrain, xTest, yTrain, yTest, cv = ML.splitTrainTestData(xPrep,y,\n",
    "                                                         printSplit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0\n",
      " 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1\n",
      " 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0] \n",
      " Balanced Accuracy:   0.7376187245590231 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       268\n",
      "           1       0.72      0.59      0.65       132\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.77      0.74      0.75       400\n",
      "weighted avg       0.78      0.79      0.78       400\n",
      " \n",
      " [[0.29 0.71]\n",
      " [0.85 0.15]\n",
      " [0.71 0.29]\n",
      " [0.56 0.44]\n",
      " [0.76 0.24]\n",
      " [0.23 0.77]\n",
      " [0.56 0.44]\n",
      " [1.   0.  ]\n",
      " [0.42 0.58]\n",
      " [0.83 0.17]\n",
      " [0.99 0.01]\n",
      " [1.   0.  ]\n",
      " [0.33 0.67]\n",
      " [0.88 0.12]\n",
      " [0.84 0.16]\n",
      " [0.4  0.6 ]\n",
      " [1.   0.  ]\n",
      " [0.63 0.37]\n",
      " [0.5  0.5 ]\n",
      " [0.19 0.81]\n",
      " [0.39 0.61]\n",
      " [0.91 0.09]\n",
      " [0.14 0.86]\n",
      " [0.43 0.57]\n",
      " [0.64 0.36]\n",
      " [0.45 0.55]\n",
      " [0.99 0.01]\n",
      " [0.39 0.61]\n",
      " [0.99 0.01]\n",
      " [0.34 0.66]\n",
      " [0.99 0.01]\n",
      " [0.68 0.32]\n",
      " [0.68 0.32]\n",
      " [0.52 0.48]\n",
      " [0.27 0.73]\n",
      " [0.55 0.45]\n",
      " [0.58 0.42]\n",
      " [0.55 0.45]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.63 0.37]\n",
      " [0.63 0.37]\n",
      " [1.   0.  ]\n",
      " [0.93 0.07]\n",
      " [1.   0.  ]\n",
      " [0.27 0.73]\n",
      " [0.99 0.01]\n",
      " [0.23 0.77]\n",
      " [0.51 0.49]\n",
      " [1.   0.  ]\n",
      " [0.89 0.11]\n",
      " [0.71 0.29]\n",
      " [0.49 0.51]\n",
      " [0.45 0.55]\n",
      " [0.62 0.38]\n",
      " [0.62 0.38]\n",
      " [0.57 0.43]\n",
      " [0.64 0.36]\n",
      " [0.46 0.54]\n",
      " [0.35 0.65]\n",
      " [0.36 0.64]\n",
      " [0.99 0.01]\n",
      " [0.32 0.68]\n",
      " [1.   0.  ]\n",
      " [0.88 0.12]\n",
      " [0.93 0.07]\n",
      " [0.43 0.57]\n",
      " [0.57 0.43]\n",
      " [0.55 0.45]\n",
      " [0.56 0.44]\n",
      " [0.4  0.6 ]\n",
      " [0.9  0.1 ]\n",
      " [1.   0.  ]\n",
      " [0.55 0.45]\n",
      " [0.52 0.48]\n",
      " [0.27 0.73]\n",
      " [0.29 0.71]\n",
      " [0.28 0.72]\n",
      " [1.   0.  ]\n",
      " [0.51 0.49]\n",
      " [0.59 0.41]\n",
      " [0.46 0.54]\n",
      " [0.75 0.25]\n",
      " [0.98 0.02]\n",
      " [1.   0.  ]\n",
      " [0.56 0.44]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.62 0.38]\n",
      " [0.89 0.11]\n",
      " [1.   0.  ]\n",
      " [0.35 0.65]\n",
      " [0.31 0.69]\n",
      " [0.41 0.59]\n",
      " [0.59 0.41]\n",
      " [0.96 0.04]\n",
      " [1.   0.  ]\n",
      " [0.96 0.04]\n",
      " [1.   0.  ]\n",
      " [0.64 0.36]\n",
      " [0.64 0.36]\n",
      " [0.71 0.29]\n",
      " [0.63 0.37]\n",
      " [0.99 0.01]\n",
      " [0.97 0.03]\n",
      " [0.69 0.31]\n",
      " [1.   0.  ]\n",
      " [0.3  0.7 ]\n",
      " [0.97 0.03]\n",
      " [0.57 0.43]\n",
      " [0.5  0.5 ]\n",
      " [0.4  0.6 ]\n",
      " [0.49 0.51]\n",
      " [0.96 0.04]\n",
      " [0.39 0.61]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.4  0.6 ]\n",
      " [0.63 0.37]\n",
      " [0.5  0.5 ]\n",
      " [0.38 0.62]\n",
      " [0.97 0.03]\n",
      " [0.97 0.03]\n",
      " [0.99 0.01]\n",
      " [0.98 0.02]\n",
      " [0.98 0.02]\n",
      " [0.6  0.4 ]\n",
      " [1.   0.  ]\n",
      " [0.52 0.48]\n",
      " [1.   0.  ]\n",
      " [0.49 0.51]\n",
      " [0.46 0.54]\n",
      " [0.97 0.03]\n",
      " [0.97 0.03]\n",
      " [1.   0.  ]\n",
      " [0.88 0.12]\n",
      " [1.   0.  ]\n",
      " [0.35 0.65]\n",
      " [0.59 0.41]\n",
      " [0.71 0.29]\n",
      " [0.9  0.1 ]\n",
      " [0.98 0.02]\n",
      " [0.65 0.35]\n",
      " [0.99 0.01]\n",
      " [0.98 0.02]\n",
      " [0.45 0.55]\n",
      " [1.   0.  ]\n",
      " [0.35 0.65]\n",
      " [0.69 0.31]\n",
      " [0.69 0.31]\n",
      " [0.33 0.67]\n",
      " [0.4  0.6 ]\n",
      " [0.71 0.29]\n",
      " [0.59 0.41]\n",
      " [1.   0.  ]\n",
      " [0.97 0.03]\n",
      " [0.53 0.47]\n",
      " [0.98 0.02]\n",
      " [0.99 0.01]\n",
      " [0.85 0.15]\n",
      " [0.49 0.51]\n",
      " [0.3  0.7 ]\n",
      " [0.43 0.57]\n",
      " [0.96 0.04]\n",
      " [0.75 0.25]\n",
      " [0.97 0.03]\n",
      " [0.69 0.31]\n",
      " [0.52 0.48]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.17 0.83]\n",
      " [0.54 0.46]\n",
      " [0.8  0.2 ]\n",
      " [0.59 0.41]\n",
      " [1.   0.  ]\n",
      " [0.62 0.38]\n",
      " [0.4  0.6 ]\n",
      " [0.78 0.22]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.41 0.59]\n",
      " [0.55 0.45]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.43 0.57]\n",
      " [0.98 0.02]\n",
      " [0.65 0.35]\n",
      " [0.35 0.65]\n",
      " [0.81 0.19]\n",
      " [0.35 0.65]\n",
      " [0.99 0.01]\n",
      " [1.   0.  ]\n",
      " [0.61 0.39]\n",
      " [0.74 0.26]\n",
      " [0.88 0.12]\n",
      " [0.48 0.52]\n",
      " [0.69 0.31]\n",
      " [0.99 0.01]\n",
      " [0.17 0.83]\n",
      " [0.56 0.44]\n",
      " [0.96 0.04]\n",
      " [0.72 0.28]\n",
      " [0.92 0.08]\n",
      " [0.47 0.53]\n",
      " [0.86 0.14]\n",
      " [0.42 0.58]\n",
      " [0.69 0.31]\n",
      " [0.57 0.43]\n",
      " [0.99 0.01]\n",
      " [1.   0.  ]\n",
      " [0.51 0.49]\n",
      " [0.54 0.46]\n",
      " [1.   0.  ]\n",
      " [0.24 0.76]\n",
      " [1.   0.  ]\n",
      " [0.86 0.14]\n",
      " [0.94 0.06]\n",
      " [1.   0.  ]\n",
      " [0.45 0.55]\n",
      " [0.68 0.32]\n",
      " [0.7  0.3 ]\n",
      " [0.78 0.22]\n",
      " [0.72 0.28]\n",
      " [0.46 0.54]\n",
      " [0.96 0.04]\n",
      " [0.51 0.49]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.36 0.64]\n",
      " [0.94 0.06]\n",
      " [0.54 0.46]\n",
      " [0.53 0.47]\n",
      " [0.65 0.35]\n",
      " [0.71 0.29]\n",
      " [0.45 0.55]\n",
      " [0.73 0.27]\n",
      " [0.99 0.01]\n",
      " [0.99 0.01]\n",
      " [0.83 0.17]\n",
      " [0.95 0.05]\n",
      " [0.97 0.03]\n",
      " [1.   0.  ]\n",
      " [0.97 0.03]\n",
      " [1.   0.  ]\n",
      " [0.6  0.4 ]\n",
      " [0.94 0.06]\n",
      " [0.28 0.72]\n",
      " [0.76 0.24]\n",
      " [0.42 0.58]\n",
      " [0.49 0.51]\n",
      " [0.59 0.41]\n",
      " [1.   0.  ]\n",
      " [0.2  0.8 ]\n",
      " [0.97 0.03]\n",
      " [0.67 0.33]\n",
      " [0.84 0.16]\n",
      " [0.58 0.42]\n",
      " [0.42 0.58]\n",
      " [1.   0.  ]\n",
      " [0.13 0.87]\n",
      " [0.61 0.39]\n",
      " [0.78 0.22]\n",
      " [0.99 0.01]\n",
      " [0.29 0.71]\n",
      " [1.   0.  ]\n",
      " [0.84 0.16]\n",
      " [0.61 0.39]\n",
      " [0.64 0.36]\n",
      " [1.   0.  ]\n",
      " [0.53 0.47]\n",
      " [0.32 0.68]\n",
      " [0.51 0.49]\n",
      " [0.99 0.01]\n",
      " [0.99 0.01]\n",
      " [1.   0.  ]\n",
      " [0.57 0.43]\n",
      " [1.   0.  ]\n",
      " [0.65 0.35]\n",
      " [1.   0.  ]\n",
      " [0.53 0.47]\n",
      " [0.45 0.55]\n",
      " [1.   0.  ]\n",
      " [0.48 0.52]\n",
      " [0.73 0.27]\n",
      " [0.43 0.57]\n",
      " [0.58 0.42]\n",
      " [0.45 0.55]\n",
      " [0.97 0.03]\n",
      " [1.   0.  ]\n",
      " [0.17 0.83]\n",
      " [0.65 0.35]\n",
      " [0.37 0.63]\n",
      " [0.26 0.74]\n",
      " [0.06 0.94]\n",
      " [0.44 0.56]\n",
      " [0.66 0.34]\n",
      " [1.   0.  ]\n",
      " [0.4  0.6 ]\n",
      " [0.32 0.68]\n",
      " [0.8  0.2 ]\n",
      " [0.99 0.01]\n",
      " [0.39 0.61]\n",
      " [0.7  0.3 ]\n",
      " [0.97 0.03]\n",
      " [1.   0.  ]\n",
      " [0.55 0.45]\n",
      " [0.59 0.41]\n",
      " [0.38 0.62]\n",
      " [0.74 0.26]\n",
      " [1.   0.  ]\n",
      " [0.54 0.46]\n",
      " [1.   0.  ]\n",
      " [0.99 0.01]\n",
      " [0.5  0.5 ]\n",
      " [0.98 0.02]\n",
      " [0.27 0.73]\n",
      " [0.57 0.43]\n",
      " [0.44 0.56]\n",
      " [0.86 0.14]\n",
      " [1.   0.  ]\n",
      " [0.47 0.53]\n",
      " [0.9  0.1 ]\n",
      " [0.98 0.02]\n",
      " [0.57 0.43]\n",
      " [0.99 0.01]\n",
      " [0.62 0.38]\n",
      " [0.99 0.01]\n",
      " [0.43 0.57]\n",
      " [0.47 0.53]\n",
      " [0.2  0.8 ]\n",
      " [0.93 0.07]\n",
      " [1.   0.  ]\n",
      " [0.37 0.63]\n",
      " [0.63 0.37]\n",
      " [1.   0.  ]\n",
      " [0.39 0.61]\n",
      " [1.   0.  ]\n",
      " [0.85 0.15]\n",
      " [0.88 0.12]\n",
      " [0.7  0.3 ]\n",
      " [0.52 0.48]\n",
      " [0.48 0.52]\n",
      " [0.81 0.19]\n",
      " [0.45 0.55]\n",
      " [0.98 0.02]\n",
      " [0.14 0.86]\n",
      " [0.23 0.77]\n",
      " [0.98 0.02]\n",
      " [0.77 0.23]\n",
      " [0.35 0.65]\n",
      " [1.   0.  ]\n",
      " [0.95 0.05]\n",
      " [0.25 0.75]\n",
      " [0.44 0.56]\n",
      " [0.42 0.58]\n",
      " [0.88 0.12]\n",
      " [0.42 0.58]\n",
      " [0.54 0.46]\n",
      " [0.22 0.78]\n",
      " [1.   0.  ]\n",
      " [0.25 0.75]\n",
      " [0.72 0.28]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.21 0.79]\n",
      " [1.   0.  ]\n",
      " [0.77 0.23]\n",
      " [0.16 0.84]\n",
      " [1.   0.  ]\n",
      " [0.63 0.37]\n",
      " [0.49 0.51]\n",
      " [0.58 0.42]\n",
      " [0.71 0.29]\n",
      " [0.57 0.43]\n",
      " [0.52 0.48]\n",
      " [0.39 0.61]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.88 0.12]\n",
      " [0.59 0.41]\n",
      " [0.74 0.26]\n",
      " [0.47 0.53]\n",
      " [1.   0.  ]\n",
      " [0.81 0.19]\n",
      " [0.39 0.61]\n",
      " [0.62 0.38]\n",
      " [1.   0.  ]\n",
      " [0.79 0.21]\n",
      " [0.99 0.01]\n",
      " [1.   0.  ]\n",
      " [1.   0.  ]\n",
      " [0.04 0.96]\n",
      " [0.99 0.01]\n",
      " [0.69 0.31]\n",
      " [0.81 0.19]\n",
      " [0.41 0.59]\n",
      " [0.87 0.13]]\n"
     ]
    }
   ],
   "source": [
    "# model in this case is the trained model \n",
    "\n",
    "# trainedModel = joblib.load(f\"RandomForestClassifier_PCA1_std.pkl\")\n",
    "# xTest = xTest.drop(columns=[\"SMILES\"])\n",
    "pred, balAcc, evaluationReport, predProb = ML.testTrainedModel(xTest, yTest, model=None, \n",
    "                                              savedModelfilename=\"RandomForestClassifier_PCA1_std.pkl\",\n",
    "                                              scaledData=True, \n",
    "                                              scaledDatafile=None)\n",
    "print(pred,'\\n', 'Balanced Accuracy:  ', balAcc,'\\n', evaluationReport, '\\n', predProb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
